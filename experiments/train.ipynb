{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T16:11:27.167993Z",
     "start_time": "2024-12-08T16:11:27.137935Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from mint.model.transformer import Transformer, TransformerConfig\n",
    "from mint.common import create_config, to_dict\n",
    "from mint.trainer import Trainer, TrainerConfig\n",
    "import os\n",
    "from mint.translator import Translator\n",
    "from mint.dataset import Dataset\n",
    "from mint.tokenizer import Tokenizer"
   ],
   "id": "fd86fb0263d8d8da",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T16:11:28.167646Z",
     "start_time": "2024-12-08T16:11:27.481565Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DATASET_PATH = \"../datasets/en_sk/\"\n",
    "\n",
    "source_tokenizer = Tokenizer.load(\"../tokenizers/en/\")\n",
    "target_tokenizer = Tokenizer.load(\"../tokenizers/sk/\")\n",
    "\n",
    "dataset = Dataset.load(DATASET_PATH)\n"
   ],
   "id": "52eb18fa707eec72",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T16:11:28.332723Z",
     "start_time": "2024-12-08T16:11:28.173067Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config = create_config(TransformerConfig())\n",
    "config.glob.d_model = 256\n",
    "config.glob.n_heads = 8\n",
    "config.glob.max_seq_len = 128 + 1\n",
    "config.glob.d_feedforward = 1024\n",
    "config.glob.p_dropout = 0.1\n",
    "\n",
    "config.encoder_config.n_blocks = 6\n",
    "config.encoder_config.vocab_size = 10000 + 1\n",
    "config.decoder_config.n_blocks = 6\n",
    "config.decoder_config.vocab_size = 10000 + 1\n",
    "\n",
    "model = Transformer(config)\n",
    "#model = Transformer.load(\"../pretrained/en_sk_small/\")\n",
    "\n",
    "\n",
    "print(f\"Number of parameters: {sum(p.numel() for p in model.parameters())}\")"
   ],
   "id": "fe589b745cb5fff9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_blocks': 6, 'vocab_size': 10001, 'transformer_block_config': {'d_model': 256, 'd_feedforward': 1024, 'p_dropout': 0.1, 'attention_config': {'n_heads': 16, 'd_model': 256, 'max_seq_len': 129, 'context_window': None}}, 'embedding_config': {'vocab_size': 10001, 'd_model': 256, 'max_seq_len': 129, 'learnable_positional_embeddings': True}}\n",
      "Number of parameters: 29905664\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-12-08T16:11:29.166851Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer_config = create_config(TrainerConfig())\n",
    "trainer_config.logger_config.experiment_name = \"exp2\"\n",
    "trainer_config.warmup_steps = 1000\n",
    "trainer_config.learning_rate = 5e-5\n",
    "trainer_config.use_cuda = True\n",
    "trainer_config.max_steps_per_epoch = 1000000 // 32 # too big dataset to run locally\n",
    "trainer_config.max_steps_per_validation = 10000 // 32\n",
    "trainer_config.batch_size = 32\n",
    "trainer = Trainer(model, dataset, **to_dict(trainer_config), source_tokenizer=source_tokenizer, target_tokenizer=target_tokenizer)\n",
    "trainer.train(10)"
   ],
   "id": "8adf32a235f1cd47",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 1/10 avg loss: 9.1027:   0%|          | 13/31250 [00:03<2:04:44,  4.17it/s]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T10:23:01.852379Z",
     "start_time": "2024-12-08T10:23:01.791495Z"
    }
   },
   "cell_type": "code",
   "source": [
    "translator = Translator(model, source_tokenizer, target_tokenizer)\n",
    "\n",
    "translator.translate(\"Good evening\", max_length=128)"
   ],
   "id": "4ac8876ad2b381ee",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m translator \u001B[38;5;241m=\u001B[39m Translator(model, source_tokenizer, target_tokenizer)\n\u001B[0;32m----> 3\u001B[0m \u001B[43mtranslator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtranslate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mGood evening\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m128\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/fit/zpja/mint/translator.py:98\u001B[0m, in \u001B[0;36mTranslator.translate\u001B[0;34m(self, text, max_length)\u001B[0m\n\u001B[1;32m     96\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtranslate\u001B[39m(\u001B[38;5;28mself\u001B[39m, text, max_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m     97\u001B[0m     source_tokens \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msource_tokenizer\u001B[38;5;241m.\u001B[39mtokenize(text, max_length\u001B[38;5;241m=\u001B[39mmax_length)\n\u001B[0;32m---> 98\u001B[0m     source_tokens \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43msource_tokens\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43munsqueeze\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    100\u001B[0m     translated_tokens \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msearch_strategy\u001B[38;5;241m.\u001B[39msearch(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel, source_tokens, max_length\u001B[38;5;241m=\u001B[39mmax_length, eos_token_id\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_tokenizer\u001B[38;5;241m.\u001B[39meos_token_id)\n\u001B[1;32m    102\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_tokenizer\u001B[38;5;241m.\u001B[39mdetokenize(translated_tokens)[\u001B[38;5;241m0\u001B[39m]\n",
      "\u001B[0;31mRuntimeError\u001B[0m: CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2e2432dd8aef37ae"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
